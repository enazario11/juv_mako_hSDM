---
title: "Mako hSDM BRT explore (CRW PAs)"
author: "Emily Nazario"
date: "`r Sys.Date()`"
format:
 html: 
  self-contained: true
editor: visual
toc: TRUE
toc-title: "On this page"
theme: yeti
fontcolor: "#134f5c"
code-block-bg: true
---

On this document, I start my initial exploration into the different model outputs, ranking of covariate influence, performance metrics, and prediction maps. This first set of models only includes extracted covariate data at a daily temporal resolution, but I am also considering exploring models that include covariate data at a seasonal or annual temporal resolution. The pseudo absences used in these models were generated using correlated random walk approaches, but another quarto document includes models with background sampling pseudo absences. Lastly, hyperparameters were tuned using the caret package and across all models, a learning rate of 0.05 and tree complexity of 3 resulted in the highest accuracy. Lastly, the 'pred_var' predictor is a random set of numbers that will be used to identify which predictor variables should be included in the final model, and which are not informative. 

The hypotheses I would like to test with these models are as follows:

**H1:** The AGI model will perform better than the dissolved oxygen and null model, and the dissolved oxygen model will perform better than the null model.

*study objective being met:* Which model performs the best and presents the best predictions (i.e., best predictive performance scores, most ecologically realistic suitability maps)? 

**H2:** The inclusion of dissolved oxygen at deeper depths will result in better/more ecologically realistic habitat suitability predictions relative to the dissolved oxygen model considering surface values alone.

*study objective being met:* How does dissolved oxygen at different depths influence habitat suitability predictions relative to oxygen at the surface?

**H3:** The inclusion of the AGI at deeper depths will result in better/more ecologically realistic habitat suitability predictions relative to the AGI model considering surface values alone.

*study objective being met:* How does the aerobic growth index (AGI; environmental oxygen supply:theoretical oxygen demand) at different depths influence habitat suitability predictions relative to the aerobic growth index at the surface? 

**H4:** There will be important relationships between dissolved oxygen/the AGI and latitude/distance to coast.

*study objective being met:* Are there any important relationships between dissolved oxygen or AGI at the surface or at depth and latitude or distance to the coast?

**H5:** The null model will predict higher habitat suitability in areas or during seasons or periods (upwelling or La Ni√±a) with lower dissolved oxygen through the water column relative to the dissolved oxygen and AGI models. 

*study objective being met:* How do the habitat suitability maps differ between the models? How do these variations compare for different points in time? 

```{r}
#| echo: false
#| warning: false
#| message: false
#| include: false

#libraries
library(tidyverse)
library(gbm)
library(dismo)
library(here)
library(terra)
library(sf)
library(tidyterra)
library(here);here <- here::here #plyr's here function masks here::here

set.seed(1004)

source(here("functions/BRT_evaluation_functions.R"))

#get test and train data sets 
#CRW data
dat_base <- readRDS(here("data/locs_brts/crw_pas/dat_base.rds")) %>% mutate(tag = as.factor(tag))
dat_do <- readRDS(here("data/locs_brts/crw_pas/dat_do.rds")) %>% mutate(tag = as.factor(tag))
dat_agi <- readRDS(here("data/locs_brts/crw_pas/dat_agi.rds")) %>% mutate(tag = as.factor(tag))

### add random variable for predictor selection ####
pred_var <- rnorm(31084, mean = 50, sd = 10)

dat_base$pred_var <- pred_var
dat_do$pred_var <- pred_var
dat_agi$pred_var <- pred_var

#split into test and train
#base
dat_train_base <- dat_base %>% sample_frac(0.75)
dat_test_base <- dat_base %>% sample_frac(0.25)

#do
dat_train_do <- dat_do %>% sample_frac(0.75)
dat_test_do <- dat_do %>% sample_frac(0.25)

#agi
dat_train_agi <- dat_agi %>% sample_frac(0.75)
dat_test_agi <- dat_agi %>% sample_frac(0.25)

#load BRT outputs
brt_outputs <- list.files(here("data/brt/mod_outputs"), full.names = TRUE)

```

# Base models

These three models represent three different options for the base model and either include spatial predictors, a tag ID predictor, both, or neither. These models were developed by splitting the data set into 75/25 train/test, and thus that is the model evaluation approach used here. However, once a model is selected, I can run additional evaluation metrics (i.e., LOO, k-fold) now depending on when that is typically completed. 

::: panel-tabset

## 0m, no spatial predictors, no tag ID predictor 
```{r}
#| warning: false
#| fig-width: 12
#| fig-height: 10

base_Nspat_Ntag <- readRDS(brt_outputs[7])

# model performance 
ggBRT::ggPerformance(base_Nspat_Ntag)

#relative influence of predictors
ggBRT::ggInfluence(base_Nspat_Ntag) 

#explore partial plots
gbm.plot(base_Nspat_Ntag, nplots = 10, plot.layout = c(3,5), write.title = FALSE) 

#find the 5 most important pairwise interactions 
base_int <- gbm.interactions(base_Nspat_Ntag)
base_int$rank.list

#predictive performance using test dataset 
preds <- predict.gbm(base_Nspat_Ntag, dat_test_base,
                     n.trees = base_Nspat_Ntag$gbm.call$best.trees,
                     type = "response")

calc.deviance(obs = dat_test_base$PA, preds) #get % deviance

dat_pred_base <- cbind(dat_test_base$PA, preds)
pres_base <- dat_pred_base[dat_pred_base[,1] == 1, 2]
abs_base <- dat_pred_base[dat_pred_base[,1] == 0, 2]

#evaluate (AUC, TSS, TPR)
e = evaluate(p = pres_base, a = abs_base)
plot(e, 'TPR')
plot(e, 'TNR')
plot(e, 'ROC')
boxplot(e)
density(e)
mean(e@TPR) #TPR
max(e@TPR + e@TNR -1) #TSS

#provides % deviance for model selection - unsure if this is different from above calc.deviance
dev_eval_brt(base_Nspat_Ntag)

#eval 75/25
eval_7525_modified(base_Nspat_Ntag, 
                 testInput = dat_test_base, 
                 gbm.y = "PA")

```

## 0m, yes spatial predictors, no tag ID predictor 
```{r}
#| warning: false
#| fig-width: 12
#| fig-height: 10

base_Nspat_Ytag <- readRDS(brt_outputs[8])

# model performance 
ggBRT::ggPerformance(base_Nspat_Ytag)

#relative influence of predictors
ggBRT::ggInfluence(base_Nspat_Ytag) 

#explore partial plots
gbm.plot(base_Nspat_Ytag, nplots = 10, plot.layout = c(3,5), write.title = FALSE) 

#find the 5 most important pairwise interactions 
base_int <- gbm.interactions(base_Nspat_Ytag)
base_int$rank.list

#predictive performance using test dataset 
preds <- predict.gbm(base_Nspat_Ytag, dat_test_base,
                     n.trees = base_Nspat_Ytag$gbm.call$best.trees,
                     type = "response")

calc.deviance(obs = dat_test_base$PA, preds) #get % deviance

dat_pred_base <- cbind(dat_test_base$PA, preds)
pres_base <- dat_pred_base[dat_pred_base[,1] == 1, 2]
abs_base <- dat_pred_base[dat_pred_base[,1] == 0, 2]

#evaluate (AUC, TSS, TPR)
e = evaluate(p = pres_base, a = abs_base)
plot(e, 'TPR')
plot(e, 'TNR')
plot(e, 'ROC')
boxplot(e)
density(e)
mean(e@TPR) #TPR
max(e@TPR + e@TNR -1) #TSS

#provides % deviance for model selection - unsure if this is different from above calc.deviance
dev_eval_brt(base_Nspat_Ytag)

#eval 75/25
eval_7525_modified(base_Nspat_Ytag, 
                 testInput = dat_test_base, 
                 gbm.y = "PA")

```


## 0m, yes spatial predictors, yes tag ID predictor 
```{r}
#| warning: false
#| fig-width: 12
#| fig-height: 10

base_Yspat_Ytag <- readRDS(brt_outputs[9])

# model performance 
ggBRT::ggPerformance(base_Yspat_Ytag)

#relative influence of predictors
ggBRT::ggInfluence(base_Yspat_Ytag) 

#explore partial plots
gbm.plot(base_Yspat_Ytag, nplots = 10, plot.layout = c(3,5), write.title = FALSE) 

#find the 5 most important pairwise interactions 
base_int <- gbm.interactions(base_Yspat_Ytag)
base_int$rank.list

#predictive performance using test dataset 
preds <- predict.gbm(base_Yspat_Ytag, dat_test_base,
                     n.trees = base_Yspat_Ytag$gbm.call$best.trees,
                     type = "response")

calc.deviance(obs = dat_test_base$PA, preds) #get % deviance

dat_pred_base <- cbind(dat_test_base$PA, preds)
pres_base <- dat_pred_base[dat_pred_base[,1] == 1, 2]
abs_base <- dat_pred_base[dat_pred_base[,1] == 0, 2]

#evaluate (AUC, TSS, TPR)
e = evaluate(p = pres_base, a = abs_base)
plot(e, 'TPR')
plot(e, 'TNR')
plot(e, 'ROC')
boxplot(e)
density(e)
mean(e@TPR) #TPR
max(e@TPR + e@TNR -1) #TSS

#provides % deviance for model selection - unsure if this is different from above calc.deviance
dev_eval_brt(base_Yspat_Ytag)

#eval 75/25
eval_7525_modified(base_Yspat_Ytag, 
                 testInput = dat_test_base, 
                 gbm.y = "PA")

```

::: 

# CMEM model w/ DO and Temp. at 0m and 250m depth. Plus all covar except AGI at those depths.

Here is the model without AGI and just DO and temperature values at 0m and 250m depth for all positions.

## DO/temp tc5, lr0.01, bf0.75

```{r}
#| warning: FALSE

#fit the model
# try(do_tc5_lr01 <- dismo::gbm.step(data = dat_train,
#                                     gbm.x = c(4, 8:12, 14:18, 20),
#                                     gbm.y = 5,
#                                     family = "bernoulli",
#                                     tree.complexity = 5,
#                                     learning.rate = 0.01,
#                                     bag.fraction = 0.75, 
#                                     silent = TRUE, 
#                                     plot.main = TRUE))

#saveRDS(do_tc5_lr01, here("data/brt/mod_bls/do_temp_tc5_lr01.rds"))

 #load model so I don't run every time
do_tc5_lr01 <- readRDS(here("data/brt/mod_bls/do_temp_tc5_lr01.rds"))

ggBRT::ggPerformance(do_tc5_lr01)

#explore outputs
gbm.plot(do_tc5_lr01, nplots = 15, plot.layout = c(3,5), write.title = FALSE) 

#relative influence of predictors
ggBRT::ggInfluence(do_tc5_lr01) 

#find the 5 most important pairwise interactions 
do_int <- gbm.interactions(do_tc5_lr01)
do_int$rank.list

#predictions
preds <- predict.gbm(do_tc5_lr01, dat_test, 
                     n.trees = do_tc5_lr01$gbm.call$best.trees, 
                     type = "response")

calc.deviance(obs = dat_test$PA, preds)

dat_pred <- cbind(dat_test$PA, preds)
pres <- dat_pred[dat_pred[,1] == 1, 2]
abs <- dat_pred[dat_pred[,1] == 0, 2]

evaluate(p = pres, a = abs)
```

# CMEM model w/ AGI and Temp. at 0m and 250m depth. Plus all covar except DO at those depths.

Here is the BRT with AGI and temp, and not DO. Here, I was interested in still including temperature because of all of the effects it has independent of its influence on the metabolic rate which is being captured by the AGI. Such influence includes temperature affects on prey species and temperature effects on the mako sharks physiology.

## AGI/temp tc5, lr0.01, bf0.75

```{r}
#| warning: FALSE

#fit the model
# try(agi_temp_tc5_lr01 <- dismo::gbm.step(data = dat_train,
#                                     gbm.x = c(4, 8:10, 12:17, 19:20),
#                                     gbm.y = 5,
#                                     family = "bernoulli",
#                                     tree.complexity = 5,
#                                     learning.rate = 0.01,
#                                     bag.fraction = 0.75,
#                                     silent = TRUE,
#                                     plot.main = TRUE))

#saveRDS(agi_temp_tc5_lr01, here("data/brt/mod_bls/agi_temp_tc5_lr01.rds"))

 #load model so I don't run every time
agi_temp_tc5_lr01 <- readRDS(here("data/brt/mod_bls/agi_temp_tc5_lr01.rds"))

ggBRT::ggPerformance(agi_temp_tc5_lr01)

#explore outputs
gbm.plot(agi_temp_tc5_lr01, nplots = 15, plot.layout = c(3,4), write.title = FALSE) 

#relative influence of predictors
ggBRT::ggInfluence(agi_temp_tc5_lr01) 

#find the 5 most important pairwise interactions 
do_int <- gbm.interactions(agi_temp_tc5_lr01)
do_int$rank.list

#predictions
preds <- predict.gbm(agi_temp_tc5_lr01, dat_test, 
                     n.trees = agi_temp_tc5_lr01$gbm.call$best.trees, 
                     type = "response")

calc.deviance(obs = dat_test$PA, preds)

dat_pred <- cbind(dat_test$PA, preds)
pres <- dat_pred[dat_pred[,1] == 1, 2]
abs <- dat_pred[dat_pred[,1] == 0, 2]

evaluate(p = pres, a = abs)
```

# CMEM model w/ AGI and Temp. at 0m depth. Plus all covar at that depth.

Above is the BRT with AGI and Temp at both 0m and 250m depth. The following models include examples where either AGI at 0m or 250m are removed to show their relative influence.

## AGI 0m tc5, lr0.01, bf0.75

```{r}
#| warning: FALSE

#fit the model
# try(agi_0_tc5_lr01 <- dismo::gbm.step(data = dat_train,
#                                     gbm.x = c(4, 8:10, 12:17, 20),
#                                     gbm.y = 5,
#                                     family = "bernoulli",
#                                     tree.complexity = 5,
#                                     learning.rate = 0.01,
#                                     bag.fraction = 0.75,
#                                     silent = TRUE,
#                                     plot.main = TRUE))

#saveRDS(agi_0_tc5_lr01, here("data/brt/mod_bls/agi_0_tc5_lr01.rds"))

 #load model so I don't run every time
agi_0_tc5_lr01 <- readRDS(here("data/brt/mod_bls/agi_0_tc5_lr01.rds"))

ggBRT::ggPerformance(agi_0_tc5_lr01)

#explore outputs
gbm.plot(agi_0_tc5_lr01, nplots = 15, plot.layout = c(3,4), write.title = FALSE) 

#relative influence of predictors
ggBRT::ggInfluence(agi_0_tc5_lr01) 

#find the 5 most important pairwise interactions 
do_int <- gbm.interactions(agi_0_tc5_lr01)
do_int$rank.list

#predictions
preds <- predict.gbm(agi_0_tc5_lr01, dat_test, 
                     n.trees = agi_0_tc5_lr01$gbm.call$best.trees, 
                     type = "response")

calc.deviance(obs = dat_test$PA, preds)

dat_pred <- cbind(dat_test$PA, preds)
pres <- dat_pred[dat_pred[,1] == 1, 2]
abs <- dat_pred[dat_pred[,1] == 0, 2]

evaluate(p = pres, a = abs)
```

# CMEM model w/ AGI at 250m plus all covar at those depths.

## AGI 250m tc5, lr0.01, bf0.75

```{r}
#| warning: FALSE

#fit the model
# try(agi_250_tc5_lr01 <- dismo::gbm.step(data = dat_train,
#                                     gbm.x = c(4, 8:10, 12, 14:17, 19:20),
#                                     gbm.y = 5,
#                                     family = "bernoulli",
#                                     tree.complexity = 5,
#                                     learning.rate = 0.01,
#                                     bag.fraction = 0.75,
#                                     silent = TRUE,
#                                     plot.main = TRUE))
# 
# saveRDS(agi_250_tc5_lr01, here("data/brt/mod_bls/agi_250_tc5_lr01.rds"))

 #load model so I don't run every time
agi_250_tc5_lr01 <- readRDS(here("data/brt/mod_bls/agi_250_tc5_lr01.rds"))

ggBRT::ggPerformance(agi_250_tc5_lr01)

#explore outputs
gbm.plot(agi_250_tc5_lr01, nplots = 15, plot.layout = c(3,4), write.title = FALSE) 

#relative influence of predictors
ggBRT::ggInfluence(agi_250_tc5_lr01) 

#find the 5 most important pairwise interactions 
do_int <- gbm.interactions(agi_250_tc5_lr01)
do_int$rank.list

#predictions
preds <- predict.gbm(agi_250_tc5_lr01, dat_test, 
                     n.trees = agi_250_tc5_lr01$gbm.call$best.trees, 
                     type = "response")

calc.deviance(obs = dat_test$PA, preds)

dat_pred <- cbind(dat_test$PA, preds)
pres <- dat_pred[dat_pred[,1] == 1, 2]
abs <- dat_pred[dat_pred[,1] == 0, 2]

evaluate(p = pres, a = abs)
```
